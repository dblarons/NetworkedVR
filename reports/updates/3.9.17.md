Attached are three diagrams that somewhat describe the architecture I am using.
Subject to change, of course, but this is my current thinking. Next week, I'll
write up a written explanation of the architecture to go along with the
diagrams.

This week, I got "V0: Proof of Concept" finished from my NetworkedVR Milestones
doc that I shared last week. What I found was that since there was no rate
limit on how many messages were being sent, the receiving peer was "fallling
behind". The object was syncing correctly, but there was a delay of perhaps
10-15 seconds because of how many messages were being received vs how many
could be processed. When I measured the output, messages were being sent on
average every 6ms.

To fix that problem, I sent messages on a fixed time interval every 33ms like
we discussed. The result was that objects synced with low latency, but since
updates were being sent every 33ms but the scene was being rendered every 6 or
so, the object was jittering.

Because of that, I need to do two things: First, I need to put the receiving
peer on a fixed 33ms time interval like the sender, and second, I need to
"lerp" (linearly interpolate) between the last frame and the next frame. The
latter improvement is only possible if I have a known, fixed time interval, so
it is dependent on the former.

In summary, I implemented part of "V2: Send updates on a fixed interval" and am
planning to do the rest of V2 (fixed interval on the client) and all of "V3:
Secondary copy interpolation" next. The attached diagrams are my planned
architecture for doing so.

I will create and send a video tomorrow morning of some of the syncing I have
described above and will get started on implementing the fixed time interval
and lerping, although I won't finish that tomorrow.

Please take a look at the diagrams and let me know what you think.
Questions/comments/concerns/feedback would be very appreciated.
